import json
import re
from datetime import datetime, timedelta, timezone
import pytz
from feishu_docx_api_handler import FeishuDocxAPIHandler, BlockType, BlockBatchUpdateRequestBuilder
import os
from dotenv import load_dotenv
#load_dotenv(override=True)

FEISHU_APP_ID = os.getenv('FEISHU_APP_ID')
FEISHU_APP_SECRET= os.getenv('FEISHU_APP_SECRET')
# åˆå§‹åŒ– FeishuDocxAPIHandler
feishu_docx_api_handler = FeishuDocxAPIHandler(FEISHU_APP_ID, FEISHU_APP_SECRET)

def batch_modify_document_blocks(document_id, blocks, modifications):
    """
    æ‰¹é‡ä¿®æ”¹æ–‡æ¡£ä¸­çš„å—ï¼Œæ ¹æ®å—çš„ç±»å‹é€‰æ‹©åˆé€‚çš„æ›´æ–°æ–¹æ³•
    :param document_id: æ–‡æ¡£ ID
    :param blocks: æ–‡æ¡£çš„å—ä¿¡æ¯
    :param modifications: åŒ…å«å— ID å’Œä¿®æ”¹å†…å®¹çš„å­—å…¸åˆ—è¡¨
    :return: æ‰¹é‡æ›´æ–°å—çš„å“åº”
    """
    # åˆ›å»ºæ‰¹é‡æ›´æ–°è¯·æ±‚æ„å»ºå™¨
    batch_update_builder = BlockBatchUpdateRequestBuilder()

    # éå†æ¯ä¸ªä¿®æ”¹é¡¹ï¼Œæ„å»ºæ‰¹é‡æ›´æ–°è¯·æ±‚
    for modification in modifications:
        block_id = modification.get("block_id")
        new_content = modification.get("new_content")
        text_style = modification.get("text_style", None)

        # æŸ¥æ‰¾å¯¹åº”çš„å—ç±»å‹
        block_type = None
        for block in blocks:
            if block.get("block_id") == block_id:
                block_type = block.get("block_type")
                break

        # æ ¹æ®å—ç±»å‹é€‰æ‹©åˆé€‚çš„æ›´æ–°æ–¹æ³•
        if block_type == BlockType.TEXT.position:
            # å¦‚æœæ˜¯æ–‡æœ¬å—ï¼Œä½¿ç”¨ add_update_text
            print(f"å— {block_id} æ˜¯æ–‡æœ¬å—ï¼Œæ›´æ–°å†…å®¹ä¸º: {new_content}")
            batch_update_builder.add_update_text(block_id, new_content, text_style)
        elif block_type == BlockType.HEADING2.position:
            # å¦‚æœæ˜¯æ ‡é¢˜å—ï¼Œä½¿ç”¨ add_update_textï¼Œå¹¶å¯èƒ½åº”ç”¨ä¸åŒçš„æ ·å¼
            print(f"å— {block_id} æ˜¯æ ‡é¢˜å—ï¼Œæ›´æ–°å†…å®¹ä¸º: {new_content}")
            batch_update_builder.add_update_text(block_id, new_content, text_style)
        elif block_type == BlockType.BULLET.position:
            # å¦‚æœæ˜¯åˆ—è¡¨å—ï¼Œä½¿ç”¨ add_update_text
            print(f"å— {block_id} æ˜¯åˆ—è¡¨å—ï¼Œæ›´æ–°å†…å®¹ä¸º: {new_content}")
            batch_update_builder.add_update_text(block_id, new_content)
        elif block_type == BlockType.CALLOUT.position:
            # å¦‚æœæ˜¯ callout å—ï¼Œä½¿ç”¨ add_update_text_elements
            print(f"å— {block_id} æ˜¯ callout å—ï¼Œæ›´æ–°å†…å®¹ä¸º: {new_content}")
            batch_update_builder.add_update_text_elements(block_id, new_content)
        else:
            # å…¶ä»–ç±»å‹çš„å—ï¼Œæš‚æ—¶ä¸å¤„ç†
            print(f"å— {block_id} çš„ç±»å‹ {block_type} æš‚ä¸æ”¯æŒæ›´æ–°")

    # æ„å»ºæ‰¹é‡æ›´æ–°è¯·æ±‚
    requests_list = batch_update_builder.build()
    print(f"æ‰¹é‡æ›´æ–°è¯·æ±‚åˆ—è¡¨: {requests_list}")

    # è°ƒç”¨æ‰¹é‡æ›´æ–°æ¥å£
    return feishu_docx_api_handler.batch_update_blocks(document_id, requests_list)



def parse_markdown_to_feishu_docx(content, report_date):
    """
    è§£æMarkdownå†…å®¹ï¼Œå°†å…¶è½¬æ¢ä¸ºé£ä¹¦æ–‡æ¡£æ—¥æŠ¥çš„è®°å½•æ ¼å¼ï¼Œå¹¶ç»„ç»‡æˆæŒ‡å®šçš„æ—¥æŠ¥æ ¼å¼ã€‚
    """
    sections = []
    products = content.split('---')  # æ¯ä¸ªäº§å“ç”¨ "---" åˆ†éš”

    for product in products:
        lines = product.strip().splitlines()
        if not lines:
            continue

        section = {}
        content_list = []
        product_website = {}
        product_hunt = {}
        image_url = ""

        for i, line in enumerate(lines):
            if line.startswith('## '):  # äº§å“åç§°å’Œé“¾æ¥
                product_name_with_link = line[3:]
                product_name = product_name_with_link.split('](')[0].strip('[')
                product_link = line.split('](')[1].strip(')')
            elif line.startswith('**æ ‡è¯­**'):
                slogan = line.split('ï¼š', 1)[1].strip()
            elif line.startswith('**ä»‹ç»**'):
                introduction = line.split('ï¼š', 1)[1].strip()
                content_list.append(introduction)
            elif line.startswith('**äº§å“ç½‘ç«™**'):
                product_website_url = line.split('](')[1].strip(')')
                product_website = {
                    "text": "ç«‹å³è®¿é—®",
                    "url": product_website_url
                }
            elif line.startswith('**Product Hunt**'):
                product_hunt_url = line.split('](')[1].strip(')')
                product_hunt = {
                    "text": "View on Product Hunt",
                    "url": product_hunt_url
                }
            elif line.startswith('![Savvyshot]') or line.startswith('!['):  # äº§å“å›¾ç‰‡
                image_url = line.split('(')[1].strip(')')
            elif line.startswith('**å…³é”®è¯**'):
                keywords = line.split('ï¼š', 1)[1].strip()
            elif line.startswith('**ç¥¨æ•°**'):
                votes = int(line.split('ğŸ”º')[1].strip())
                content_list.append(f"ç¥¨æ•°ï¼šğŸ”º{votes}")
            elif line.startswith('**æ˜¯å¦ç²¾é€‰**'):
                featured = 'æ˜¯' if 'æ˜¯' in line else 'å¦'
            elif line.startswith('**å‘å¸ƒæ—¶é—´**'):
                raw_date = line.split('ï¼š', 1)[1].strip()
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ—¥æœŸå’Œæ—¶é—´éƒ¨åˆ†
                date_match = re.search(r'(\d{4}å¹´\d{2}æœˆ\d{2}æ—¥)\s*(PM|AM)?(\d{2}:\d{2})?', raw_date)
                if date_match:
                    # æå–æ—¥æœŸéƒ¨åˆ†
                    date_str = date_match.group(1)
                    time_str = date_match.group(3) if date_match.group(3) else "00:00"  # å¦‚æœæ²¡æœ‰æ—¶é—´ï¼Œé»˜è®¤æ˜¯00:00
                    am_pm = date_match.group(2)  # AM/PM æ ‡è®°

                    # å°†æ—¥æœŸå’Œæ—¶é—´æ‹¼æ¥æˆå®Œæ•´çš„å­—ç¬¦ä¸²
                    full_datetime_str = f"{date_str} {time_str}"
                    
                    # è§£æä¸º datetime å¯¹è±¡
                    parsed_date = datetime.strptime(full_datetime_str, '%Yå¹´%mæœˆ%dæ—¥ %H:%M')

                    # å¦‚æœæ˜¯ PM ä¸”æ—¶é—´å°äº 12 ç‚¹ï¼Œè½¬æ¢ä¸º 24 å°æ—¶åˆ¶
                    if am_pm == 'PM' and parsed_date.hour < 12:
                        parsed_date = parsed_date.replace(hour=parsed_date.hour + 12)
                    elif am_pm == 'AM' and parsed_date.hour == 12:
                        # å¦‚æœæ˜¯ AM ä¸”æ—¶é—´æ˜¯ 12 ç‚¹ï¼Œè½¬æ¢ä¸º 0 ç‚¹
                        parsed_date = parsed_date.replace(hour=0)

                    # è®¾ç½®ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)
                    beijing_tz = pytz.timezone('Asia/Shanghai')
                    localized_date = beijing_tz.localize(parsed_date)

                    # è½¬æ¢ä¸º UTC æ—¶é—´æˆ³
                    unix_timestamp = int(localized_date.astimezone(pytz.utc).timestamp())
                    content_list.append(f"å‘å¸ƒæ—¶é—´ï¼š{unix_timestamp*1000}")  # éœ€è¦è½¬æ¢ä¸ºæ¯«ç§’
                else:
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ—¥æœŸï¼Œä¿ç•™åŸå§‹çš„å‘å¸ƒæ—¶é—´
                    content_list.append(f"å‘å¸ƒæ—¶é—´ï¼š{raw_date}")

        # ç»„è£… section
        section['heading'] = product_name + "ï¼š" + slogan
        section['content'] = content_list
        section['product_website'] = product_website
        section['product_hunt'] = product_hunt
        section['image_url'] = image_url

        if section:
            sections.append(section)

    # ç»„è£…æœ€ç»ˆçš„ report_data
    report_data = {
        "title": "æ¯æ—¥äº§å“æŠ¥å‘Š",
        "date": report_date,
        "sections": sections
    }

    return report_data


def extract_top_projects_from_report(date_block_id, report_data, block_ids, top_n=3):
    """
    ä» parse_markdown_to_feishu_docx å‡½æ•°çš„è¾“å‡ºä¸­æå–å†…å®¹ï¼Œå¹¶ç”Ÿæˆé£ä¹¦æ–‡æ¡£çš„ä¿®æ”¹åˆ—è¡¨ã€‚
    å…è®¸é€šè¿‡ top_n å‚æ•°æŒ‡å®šæå–çš„é¡¹ç›®æ•°é‡ï¼Œå¹¶é€šè¿‡ block_ids æ•°ç»„ä¸ºæ¯ä¸ªé¡¹ç›®åŠ¨æ€åˆ†é… block_idã€‚
    """
    modifications = [
        # æ—¥æœŸå—
        {
            "block_name": "æ—¥æœŸ",
            "block_id": date_block_id,  # å— ID
            "new_content": [
                {"content": report_data["date"], "text_element_style": {"bold": False}}  # ä½¿ç”¨æŠ¥å‘Šä¸­çš„æ—¥æœŸ
            ]
        }
    ]
    
    # é¡¹ç›®æ¨¡æ¿
    project_template = [
        {
            "block_name": "é¡¹ç›® {index}ï¼šåå­—",
            "block_id": "test",  # å— ID
            "new_content": [
                {"content": "{name}ï¼š{tagline}", "text_element_style": {"bold": False}}  # æ–°çš„æ ‡é¢˜å†…å®¹
            ]
        },
        {
            "block_name": "é¡¹ç›® {index}ï¼šç¥¨æ•°",
            "block_id": "test",  # å— ID
            "new_content": [
                {"content": "ç¥¨æ•°ï¼šğŸ”º{votes}", "text_element_style": {"bold": False}}  # æ›´æ–°ç¥¨æ•°
            ]
        },
        {
            "block_name": "é¡¹ç›® {index}ï¼šæè¿°",
            "block_id": "test",  # å— ID
            "new_content": [
                {"content": "{description}", "text_element_style": {"bold": False}}  # æ›´æ–°æè¿°
            ]
        },
        {
            "block_name": "é¡¹ç›® {index}ï¼šç½‘å€",
            "block_id": "test",  # å— ID
            "new_content": [
                {"content": "ç½‘å€ï¼š", "text_element_style": {"bold": False}},
                {"content": "æŸ¥çœ‹", "text_element_style": {
                    "bold": False,
                    "link": {"url": "{url}"}  # æ›´æ–°ç½‘å€
                }}
            ]
        }
    ]
    
    # éå†æŠ¥å‘Šä¸­çš„æ¯ä¸ª sectionï¼Œæœ€å¤šæå– top_n ä¸ªé¡¹ç›®
    for i, section in enumerate(report_data["sections"][:top_n], start=1):
        name, tagline = section["heading"].split("ï¼š", 1)  # æå–äº§å“åç§°å’Œæ ‡è¯­
        description = section["content"][0]  # äº§å“ä»‹ç»
        votes = section["content"][1].split("ğŸ”º")[1]  # æå–ç¥¨æ•°
        url = section["product_website"]["url"]  # äº§å“ç½‘ç«™é“¾æ¥
        
        
        # å¡«å……æ¯ä¸ªé¡¹ç›®çš„å­—æ®µ
        for j, template in enumerate(project_template, start=1):
            # è·å–å½“å‰é¡¹ç›®çš„ block_id
            block_id = block_ids[i - 1][j - 1] if j - 1 < len(block_ids[i - 1]) else "default_block_id"  # å¦‚æœ block_ids ä¸å¤Ÿç”¨ï¼Œä½¿ç”¨é»˜è®¤å€¼            
            filled_template = {
                "block_name": template["block_name"].format(index=i),
                "block_id": block_id,  # ä½¿ç”¨åŠ¨æ€åˆ†é…çš„ block_id
                "new_content": [
                    {
                        "content": template["new_content"][0]["content"].format(
                            index=i, name=name, tagline=tagline, votes=votes, description=description, url=url
                        ),
                        "text_element_style": {"bold": False}
                    }
                ]
            }
            
            # æ£€æŸ¥ new_content åˆ—è¡¨æ˜¯å¦æœ‰ç¬¬äºŒä¸ªå…ƒç´ ï¼Œå¹¶ä¸”è¯¥å…ƒç´ åŒ…å« "link"
            if len(template["new_content"]) > 1 and "link" in template["new_content"][1]["text_element_style"]:
                filled_template["new_content"].append({
                    "content": "æŸ¥çœ‹",
                    "text_element_style": {
                        "bold": False,
                        "link": {"url": url}
                    }
                })
            
            modifications.append(filled_template)
    
    return modifications


# è¯»å–æœ¬åœ°Markdownæ–‡ä»¶
def read_markdown_file(file_path):
    """
    ä»æœ¬åœ°æ–‡ä»¶è¯»å–Markdownå†…å®¹
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

# è¯»å–å¹¶è§£æ Markdown æ–‡ä»¶
def process_markdown_file_for_date(startdate, block_ids, date_block_id, document_id, blocks):
    """
    å¤„ç†æŒ‡å®šæ—¥æœŸçš„ Markdown æ–‡ä»¶ï¼Œç”Ÿæˆ report_data å¹¶åº”ç”¨åˆ°é£ä¹¦æ–‡æ¡£ä¸­ã€‚
    :param startdate: å¼€å§‹æ—¥æœŸ
    :param block_ids: æ¯ä¸ªé¡¹ç›®çš„ block_id åˆ—è¡¨
    :param date_block_id: æ—¥æœŸå—çš„ block_id
    :param document_id: é£ä¹¦æ–‡æ¡£çš„ ID
    :param blocks: æ–‡æ¡£çš„å—ä¿¡æ¯
    """
    # æ ¼å¼åŒ–æ—¥æœŸ
    startdate_str = startdate.strftime('%Y-%m-%d')

    # è·å–æœ€æ–°çš„Markdownæ–‡ä»¶å†…å®¹
    file_path = f'data/producthunt-daily-{startdate_str}.md'
    markdown_content = read_markdown_file(file_path)

    # ä»Markdownç”Ÿæˆreport_data
    report_date = startdate_str
    report_data = parse_markdown_to_feishu_docx(markdown_content, report_date)

    # ä»report_dataç”Ÿæˆmodificationsï¼Œæå–å‰3ä¸ªé¡¹ç›®
    modifications = extract_top_projects_from_report(date_block_id, report_data, block_ids)

    # è°ƒç”¨æ‰¹é‡ä¿®æ”¹æ–¹æ³•
    batch_modify_document_blocks(document_id, blocks, modifications)


# å¤„ç†å¤šä¸ªæ—¥æœŸçš„ Markdown æ–‡ä»¶
def process_multiple_dates(document_id, blocks, date_block_ids, block_ids_list, days_to_process=0):
    """
    å¤„ç†å¤šä¸ªæ—¥æœŸçš„ Markdown æ–‡ä»¶ï¼Œå¹¶å°†å…¶å†…å®¹åº”ç”¨åˆ°é£ä¹¦æ–‡æ¡£ä¸­ã€‚
    :param document_id: é£ä¹¦æ–‡æ¡£çš„ ID
    :param blocks: æ–‡æ¡£çš„å—ä¿¡æ¯
    :param date_block_ids: æ¯ä¸ªæ—¥æœŸå¯¹åº”çš„å— ID åˆ—è¡¨
    :param block_ids_list: æ¯ä¸ªé¡¹ç›®çš„ block_id åˆ—è¡¨
    :param days_to_process: è¦å¤„ç†çš„å¤©æ•°
    """
    today = datetime.now(timezone.utc)

    for i in range(3):
        # è·å–å¼€å§‹æ—¥æœŸ
        startdate = today - timedelta(days=i + days_to_process)

        # è·å–å¯¹åº”çš„ block_id
        date_block_id = date_block_ids[i]
        block_ids = block_ids_list[i]

        # å¤„ç†æŒ‡å®šæ—¥æœŸçš„ Markdown æ–‡ä»¶
        process_markdown_file_for_date(startdate, block_ids, date_block_id, document_id, blocks)


# ä¸»å‡½æ•°
def main():

    # æŒ‡å®šè¦è·å–çš„æ–‡æ¡£ ID
    document_id = "S2mTdzFrToxGSjx4aAgc4fDBnjb"
    document_blocks = feishu_docx_api_handler.get_document_blocks(document_id)
    blocks = document_blocks.get('data', {}).get('items', [])

    # é¢„å®šä¹‰çš„ block_id æ•°ç»„
    date_block_ids = [
        "L2PYd2YnAocH13x5dP0c9S5anGk",  # ç¬¬ä¸€å¤©çš„æ—¥æœŸå— ID
        "WeNFdCfZhoKb1sx39Fzclvqqnkb",  # ç¬¬äºŒå¤©çš„æ—¥æœŸå— ID
        "Pfjhdjay4o54UzxEpZ8cEaU0nwd"   # ç¬¬ä¸‰å¤©çš„æ—¥æœŸå— ID
    ]

    block_ids_list = [
        [
            [
            "DQu8dWOQKoGfH0x07pccVXqBnDc",
            "UPksdUdI0owjGZxVFszcdFQznjf",
            "XWlkdXv1WoDxiXxC6uQcofySnhf",
            "Ih7idClESoKYWcxTq4acaCYPngc"
            ],
            [
            "KjtldZmafoSuOoxRwRccgtmhnth",
            "REyGd1lUxoSDCvxu16icxpmznLf",
            "IM5odauOSotDTdxhRmecW9LlnGf",
            "LjaydEnyto0gtlxmUAPcisGnndh"
            ],
            [
            "Jk98depSKoQHMFxqlxXcCBd0npb",
            "CWGDdSxp9ouLCZxClJacl48anYd",
            "X94IdhD86o0yhTxR8RicNZXZnXe",
            "LbytdSH8Tos9xhx9JrecpOY4nPe"
            ]
        ],
        [
            [
            "LXcPduKZFo99SXxUapicphiYndb",
            "JL2Odru6Mo1kbFx0onvcum4SnGe",
            "DJvjdOIDEoGDSKxoUSzckEcKnGe",
            "OBOcd9274o8oZVxmyuEc9Hqnnqv"
            ],
            [
            "YyvCd7AV6ocMtAxsccGccB54npC",
            "EST7dineBovqT4xQlZWcHzW3nef",
            "AFnOdLAeZoK9RqxzwWYcOimvnOc",
            "DaVqdfopRoduaNxiqjlc7hVWnag"
            ],
            [
            "PUtjdu7guob9e5x3xzAcPYdgnZg",
            "MCmCdjW67oUzrnxl8aAcQhDon8d",
            "KaujdbRHoo9IiVxpgnqcqUebn2e",
            "PjfadZe7koDwYkxIli6cn1j7nHh"
            ]
        ],
        [
            [
            "GygTdXzXHoYoI4xfhmpcoVMknrg",
            "QRMydAKMPo9QPgxpfwvciwPVnde",
            "THIUdjHpDo6MkXxMfLlclkUcnIf",
            "EmW3d7yKVoiDiYxXDSkcCZconSc"
            ],
            [
            "GZsVdwntsovexqxqu92cpUxgn9g",
            "ZbavdPa54o8yrpxJ2Kdc1jiMnPg",
            "S2jDdRFMUottVEx09TgclMDTn9c",
            "Cy3MdaZMQovDAix2uXOco9MLnZs"
            ],
            [
            "XNgHd7N8JoOD3exYtjDci26En7d",
            "VBcpdCnYOoFjCGxgJL8cynVqnRd",
            "VKSud6Hrbogx0MxVEdScA9gnnfe",
            "VtG1dz4euo9zLfxMaOXc4yGAnIg"
            ]
        ]
    ]

    # å¤„ç†æœ€è¿‘ 3 å¤©çš„ Markdown æ–‡ä»¶
    process_multiple_dates(document_id, blocks, date_block_ids, block_ids_list, days_to_process=0)


if __name__ == "__main__":
    main()